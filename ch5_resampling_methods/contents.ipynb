{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# measuring accuracy or suitablility of a model\n",
    "- fitting the same model across different sampling sets to get a better understanding of the accuracy of the model and helps tuning parameters\n",
    "\n",
    "## 1. cross validation\n",
    "- holding out a subset of training data to act as test data\n",
    "\n",
    "### validation set approach\n",
    "- by randomly dividing a dataset into training or testing data.\n",
    "- then computing the mean sqaured error of the models\n",
    "- repeating it 10 times show that in the case of Auto dataset, 2nd degree polynomials seem to work best\n",
    "- but the range is much larger than the mean squared error for a single split\n",
    "- tends to overestimate test error\n",
    "- cross validation addresses these issues.\n",
    "\n",
    "### leave one out cross-validation\n",
    "- leave one sample out and train the rest\n",
    "- find the mean squared error\n",
    "- low bias, high variance, as it contains most samples in the dataset\n",
    "- however, with the large overlapping samples outputs tend to be largely correlated.\n",
    "\n",
    "### k-fold cross validation\n",
    "- divide into k equal sections\n",
    "- pick one as testing set and the rest as training set.\n",
    "- results in k different iterations of the data model\n",
    "- average mean squared error in each model is measured.\n",
    "- commonly uses 5 <= k <= 10\n",
    "- disadvantage: doesn't measure the model at 100% of the dataset.\n",
    "- if model picks well-performing attributes before fitting the model, a common mistake is to apply k-fold validation after the selection\n",
    "- instead should apply to both processes of filtering and fitting.\n",
    "- because the process of picking predictors often picks those that optimise overall MSE/k-fold validation, therefore may only be suited to the specific training set instead of the entire population\n",
    "\n",
    "### cross validation on classification\n",
    "- computed as the average error rate of each iteration of training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bootstrap\n",
    "\n",
    "- measures uncertainty associated to a given estimator or machine learning method\n",
    "\n",
    "e.g. estimate SE of coefficients from a LR fit\n",
    "- easily applied to range of methods including ones with difficult to obtain variability\n",
    "\n",
    "### methodology\n",
    "1. take a dataset Z of n observations\n",
    "2. create a new sample of size n with sampling by replacement, creating Z*1\n",
    "3. calculate $\\alpha *1$ as the value that minimises the Variance of Z*1\n",
    "4. repeat many times and compute standard error with all estimates of a*r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Coding Cross Validation and Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from ISLP import load_data\n",
    "from ISLP.models import (ModelSpec as MS, summarize, poly)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from sklearn.model_selection import (cross_validate, KFold, ShuffleSplit)\n",
    "from sklearn.base import clone\n",
    "from ISLP.models import sklearn_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Auto = load_data('Auto')\n",
    "Auto_train, Auto_valid = train_test_split(Auto, test_size=196, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_mm = MS(['horsepower'])\n",
    "X_train = hp_mm.fit_transform(Auto_train)\n",
    "y_train = Auto_train.mpg\n",
    "model = sm.OLS(y_train, X_train)\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.7554079592286"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid = hp_mm.transform(Auto_valid)\n",
    "y_valid = Auto_valid.mpg\n",
    "valid_pred = results.predict(exog=X_valid)\n",
    "np.mean((y_valid - valid_pred) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- estimating error for higher degree polynomials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function returning MSE on the test set\n",
    "\n",
    "def eval_mse(terms, response, train, test):\n",
    "    mm = MS(terms)\n",
    "    X_train = mm.fit_transform(train)\n",
    "    y_train = train[response]\n",
    "    X_test = mm.transform(test)\n",
    "    y_test = test[response]\n",
    "\n",
    "    results = sm.OLS(y_train, X_train).fit()\n",
    "    test_pred = results.predict(exog=X_test)\n",
    "\n",
    "    return np.mean((y_test - test_pred) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20.75540796, 16.94510676, 16.97437833])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the function eval_mse to find validation error for degrees of polynomials\n",
    "\n",
    "mse = np.zeros(3)\n",
    "for idx, deg in enumerate(range(1, 4)):\n",
    "    mse[idx] = eval_mse([poly('horsepower', deg)], 'mpg', Auto_train, Auto_valid)\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- even though is possible for all packages, sklearn has better support for cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.23151351792923"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearn_sm() is a wrapper to enable use of sm models in sklearn\n",
    "\n",
    "hp_model = sklearn_sm(sm.OLS, MS(['horsepower']))\n",
    "\n",
    "X, Y = Auto.drop(columns=['mpg']), Auto.mpg\n",
    "cv_res = cross_validate(hp_model, X, Y, cv=Auto.shape[0])\n",
    "cv_err = np.mean(cv_res['test_score'])\n",
    "cv_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.23151352, 19.24821312, 19.33498406, 19.42443034, 19.0332226 ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting for different degree polynomials\n",
    "\n",
    "cv_error = np.zeros(5)\n",
    "H = np.array(Auto['horsepower'])\n",
    "M = sklearn_sm(sm.OLS)\n",
    "for i, d in enumerate(range(1, 6)):\n",
    "    X = np.power.outer(H, np.arange(d+1))\n",
    "    M_CV = cross_validate(M, X, Y, cv=Auto.shape[0])\n",
    "    cv_error[i] = np.mean(M_CV['test_score'])\n",
    "\n",
    "cv_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_error = np.zeros(5)\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "\n",
    "for i, d in enumerate(range(1, 6)):\n",
    "    X = np.power.outer(H, np.arange(d+1))\n",
    "    M_CV = cross_validate(M, X, Y, cv=cv)\n",
    "    cv_error[i] = np.mean(M_CV['test_score'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio = load_data('Portfolio')\n",
    "def alpha_func(D, idx):\n",
    "    cov_ = np.cov(D[['X', 'Y']].loc[idx], rowvar=False)\n",
    "    return ((cov_[1, 1] - cov_[0, 1]) / (cov_[0, 0] + cov_[1, 1] - 2 * cov_[0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57583207459283"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_func(portfolio, range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6074452469619002"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "alpha_func(portfolio, rng.choice(100, 100, replace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding standard error\n",
    "def boot_SE(func, D, n=None, B=1000, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    first_, second_ = 0, 0\n",
    "    n = n or D.shape[0]\n",
    "    for _ in range(B):\n",
    "        idx = rng.choice(D.index, n, replace=True)\n",
    "        value = func(D, idx)\n",
    "        first_ += value\n",
    "        second_ += value ** 2\n",
    "    return np.sqrt(second_ / B - (first_ / B) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09118176521277516"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_SE = boot_SE(alpha_func, portfolio, B=1000, seed=0)\n",
    "alpha_SE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- estimating accuracy of LR model\n",
    "    - write a function taking D and idx as only arguments\n",
    "    - then return the mean squared error of the model\n",
    "    - bootstrap specific regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot_OLS(model_matrix, response, D, idx):\n",
    "    D_ = D.loc[idx]\n",
    "    Y_ = D_[response]\n",
    "    X_ = clone(model_matrix).fit_transform(D_)\n",
    "    return sm.OLS(Y_, X_).fit().params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using partial() to freeze first two arguments\n",
    "\n",
    "hp_func = partial(boot_OLS, MS(['horsepower']), 'mpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39.88064456, -0.1567849 ],\n",
       "       [38.73298691, -0.14699495],\n",
       "       [38.31734657, -0.14442683],\n",
       "       [39.91446826, -0.15782234],\n",
       "       [39.43349349, -0.15072702],\n",
       "       [40.36629857, -0.15912217],\n",
       "       [39.62334517, -0.15449117],\n",
       "       [39.0580588 , -0.14952908],\n",
       "       [38.66688437, -0.14521037],\n",
       "       [39.64280792, -0.15555698]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "np.array([hp_func(D=Auto, idx=rng.choice(392, 392, replace=True)) for _ in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept     0.857854\n",
       "horsepower    0.007458\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use boot SE to find the SE for the 10 bootstrap sets\n",
    "\n",
    "hp_se = boot_SE(hp_func, Auto, B=1000, seed=0)\n",
    "hp_se"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "islp_20241005",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
